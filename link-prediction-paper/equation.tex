\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e, times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{color}
\usepackage{cite}
\usepackage{epsfig, graphics}
\usepackage{bm}
\usepackage{enumitem}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\title{Predicting Movie Rating with Parallel Stochastic Gradient Descent \& Hybrid Matrix Factorization}

\author{
Kanit Wongsuphasawat, Supasorn Suwajanakorn \\
% \thanks{ Use footnote for providing further information
% about author (webpage, alternative address)---\emph{not} for acknowledging
% funding agencies.} \\
Computer Science \& Engineering\\
University of Washington\\
\texttt{\{supasorn,kanitw\}@cs.washington.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\U}{U}
\newcommand{\M}{M}
\newcommand{\kernel}{K}
\newcommand{\normv}[1]{\|#1\|_2}

\nipsfinalcopy % Uncomment for camera-ready version

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}

\maketitle

\section{Introduction}

Our goal is to predict movie ratings for each user based on previous ratings
and movie metadata including genres and user-provided tags. We model the
prediction problem as a matrix factorization problem and explore a pure matrix
factorization and a hybrid matrix factorization while attempt to address the
following problems:

\textbf{1) Run-time Performance.}
We implemented three parallelization techniques that enable fast
learning algorithm:
(a) Distributed Stochastic Gradient Descent (DSGD),
(b) Non-locking Stochastic Multi-machine Algorithm for Asynchronous and Decentralized Matrix Completion (NOMAD) with dynamic load balancing, and
(c) GraphLab Create with edge-centric update.
We compared performance of these techniques and also use them to compare the accuracy between pure and hybrid matrix factorization.


\textbf{2) Cold-Start Problem.}
A common problem for matrix factorization-based method for collaborative
filtering is the inability to address unseen items (movies in our case) or
users.  We address this problem by using a hybrid model combining matrix
factorization and content-based filtering techniques using metadata as
features. To address high dimensionality, we compress tags feature vectors
using hash-kernel techniques~\cite{shi:hashkernels}.  We compare results
from the hybrid model with pure matrix factorization.  The results show that \todo{summarize result here}


\section{Dataset \& Preprocessing}

We use the MovieLens 20M\footnote{http://grouplens.org/datasets/movielens/}
as our benchmark dataset.  The dataset contains the following features:

\begin{itemize}[leftmargin=15pt]
	\item Over 20 million ratings for 27,278 movies ($n_m$) by 138,493 users ($n_u$).
	0.5\% of the rating matrix $R$ has non-zero values.  The ratings ranges from 0.5 to 5.
% 	We normalize the rating by setting each rating to
% \begin{align}
% 	 R = \frac{R_{original} - 0.5}{4.5}
% \end{align}

	\item Genres of each movie, given as a set of genres associated with each
movie. There are 19 unique genres ($n_g$).

	\item 65,564 user-provided tags (37,896 unique tags), such as ``dark hero'', ``bollywood'',
	``conspiracy theory''.  We remove space and symbols for each tag to remove duplicate entities.

	\item All users included in the data have rated at least 20 movies.
\end{itemize}

Our model will be evaluated on both the cold-start problem and the standard
prediction problem (in which we predict unknown ratings for already-seen
movies in the training set). To achieve that, we generated two datasets from the
rating matrix R (of rank $n_u \times n_m$):

\textbf{1) Training and test data set for the standard problem ($D_s$).} For
the standard problem, we obtain a test set ($D_{s,test}$) by taking out 20\%
of all the ratings from the rating matrix and use the remaining as the
training set ($D_{s,train}$). Due to our limited computational resources and
time, it is infeasible to search for optimal parameters on the full training
set. Therefore, we create a random submatrix for validating model $D^*_{s}$ by
sampling 20\% of movies and users and split $D^*_{s}$ into $D^*_{s,train}$ and
$D^*_{s,validate}$ using $4:1$ ratio. Once all hyper-parameters are learned,
we re-train our model on the full training set ($D_{s,train}$) and evaluate on
the test set ($D_{s,test}$).

\textbf{2) Training and test data set for the cold-start problem ($D_c$).} For
the cold-start problem, we obtain a test set ($D_{c,test}$) by taking out 20\%
of   the {\em columns} from the rating matrix and use the remaining as the
training set ($D_{c,train}$). This assures that all the ratings of each movie
in the test set have not been included for model learning.   Similar to $D_s$, we create a submatrix for validating model $D^*_{c}$ using the same sampling method and split them into $D^*_{s,train}$ and $D^*_{s,validate}$ using $4:1$ ratio for
selecting optimal parameters.



\section{Formulation}

\subsection{Pure Matrix Factorization}

We first formulate rating prediction task as a pure matrix factorization
problem  where $r_{um}$ is the user $u$'s rating for movie $m$ while $L_u,
R_m \in \mathbb{R}^k$ are $k$ dimensional latent vectors associated with
user $u$ and movie $m$.

The objective function is
\begin{align}
\min_{L, R} \frac{1}{2}\sum_{r_{um}} \left\{(L_u \cdot R_m - r_{um})^2\right\}
	+ \frac{\lambda_u}{2}\|L\|^2_F + \frac{\lambda_m}{2}\|R\|^2_F \label{eq:mf}
\end{align}

where $\lambda_u$ and $\lambda_m$  are regularization parameters for each latent matrix.

\subsection{Hybrid Matrix Factorization}

In MovieLens data, each movie $m$ has a set of genres and user-specified
tags. This implicit information is useful in scenario where we try to
predict ratings for unobserved movies that have similar tags to the existing
ones and can be used in a feature-based model to complement the prediction.

For each movie, we model the genres as a membership boolean vector $\bm{g_m} \in
\{0,1\}^{19}$ and tags count vector $\bm{t_m} \in \mathbb{N}_0^{465,564}$ where
$t_m^j$ represents the number of times that movie $m$ is tagged by tag $j$.  To
compress the tag vector, we use hash kernel to project each
$\bm{t_m}$ to a 40-dimensional kernel vector $\kernel(\bm{t_m})$ using hash
function $h$ and $\xi$ sign hash function.
\begin{align}
	\kernel_i(\bm{x}) &= \sum_{j:h(j)=i} \xi(j) \bm{x_j}
\end{align}
\begin{center}
where $h: X \rightarrow \{1, ..., 40\}$ and $\xi: X \rightarrow \{1,-1\}$.
\end{center}

We then normalize the genres membership vector and the tags kernel vector using $L_2$ norm.
\begin{align}
	\bm{\hat{g}_m} = \frac{\bm{\hat{g}_m}}{\normv{\bm{\hat{g}_m}}},
	\hat{\kernel}(\bm{t_m}) = \frac{\kernel(\bm{t_m})}{\|\kernel(\bm{t_m})\|_2}
\end{align}

After compression, we can model movie feature vector for each movie $\phi(m)$ as normalized concatenation of the genres membership vector and the tags kernel vector. As both vectors have $L_2$ norm of $1$, we can normalize the concatenation by dividing by square root of 2.
\begin{align}
	\phi(m) = \frac{1}{\sqrt{2}} [\bm{\hat{g}_m}\ \ \hat{\kernel}(\bm{t_m})]
\end{align}

With these features, we model the interaction as a dot product $w \cdot
\phi(m)$ where $w$ is a weight vector associated with the feature vector.
However, the weight might vary across different users and movies. Different
users might have varied preference for each movie genre and tag. For
example, one might prefer action movies while another might prefer dramas.
Similarly, different movie might have varied interaction with its own
feature. For example, consider a scenario where we try to predict ratings of
a user $u$ for two different movies where one of the movies stars a very
famous actress and the other stars a less well-known set of casts. One can
imagine that people may pay less attention to genres if a movie stars their
favorite actors/actresses and more attention when they do not know much
about the film casts. This suggests that movie-specific biases can be
beneficial for modeling this kind of behavior.  Thus we define the weight
vector $w = w_u + w_m$ where $w_u$ is a weight vector associated with user
$u$ and  $w_m$ is a weight vector associated with movie $m$

Moreover, since part of the observed variation in the ratings is attributed
to similar systematic biases \cite{koren:matrix} where certain users tend to
rate, on average, higher (or lower) than their peers or certain movies tend
to be highly rated, we incorporate user- and movie-specific bias terms
($b_u$ and $b_m$) in the rating in the final prediction so that the dot
product of the movie and user latent variables instead describes the
deviation from the user/movie's mean rating.

A true first-order approximation of these systematic biases includes a
global bias or weight shared by all users. However, we use a slightly
different approximation that folds the global bias into individual biases so
that learning can be done efficiently due to the ability to  partition the
data into independent sub-problems. This allows sequential-consistent
learning algorithms to run with fewer blocking operations or enable other
bulk or distrubuted synchronization strategies such as Distributed
Stochastic Gradient Descent (DSGD)~\cite{gemulla2011large}, or
NOMAD~\cite{yun2013nomad}.

Our final unified collaborative filtering model combines matrix
factorization with a feature-based learning to address cold-start problem:

\begin{multline}
\min_{L, R, b_u, b_v, w_u, w_m} \frac{1}{2}\sum_{r_{um}} \left\{(L_u \cdot R_m + (w_u + w_m) \cdot \phi(m) + b_u + b_m - r_{um})^2\right\}\\ + \frac{\lambda_u}{2}\|L\|^2_F + \frac{\lambda_m}{2}\|R\|^2_F + \frac{\lambda_{w_u}}{2}\sum_u\|w_u\|^2_2 + \frac{\lambda_{w_m}}{2}\sum_m\|w_m\|^2_2\label{eq:main}
\end{multline}

where
\begin{itemize}
	\item $L_u, R_m \in \mathbb{R}^k$ are $k$ dimensional latent vectors associated with user $u$ and movie $m$.
	\item $w_u,w_m \in \mathbb{R}^{dim(\phi)}$ are latent feature weights.
	\item $b_u, b_m \in \mathbb{R}$ are individual and movie-specific biases for the rating $r_{um}$.
	\item $\phi(m)$ is a feature containing movie genres and user-specified tags.
	\item $\lambda_u$, $\lambda_m$, $\lambda_{w_u}$, and $\lambda_{w_m}$ are regularization parameters.
\end{itemize}

\section{Learning}

\textbf{Update Equation.}   We use stochastic gradient descent to optimize
Equation $\ref{eq:main}$. The update equations for the latent variables given
a rating $r_{um}$ are:

\begin{align}
L_u^{i+1} &= L_u^{i} - \eta ( \epsilon_{um} R_m  + \lambda_u L_u^i) \label{eq:update1st}\\
R_m^{i+1} &= R_m^{i} - \eta ( \epsilon_{um} L_u  + \lambda_u R_m^i)\\
w_u^{i+1} &= w_u^{i} - \eta ( \epsilon_{um} \phi(m) + \lambda_{w_u} w_u^i)\\
w_m^{i+1} &= w_m^{i} - \eta ( \epsilon_{um} \phi(m) + \lambda_{w_m} w_m^i)\\
b_u^{i+1} &= b_u^{i} - \eta \epsilon_{um}\\
b_m^{i+1} &= b_m^{i} - \eta \epsilon_{um} \label{eq:updatelast}
\end{align}
where
\begin{align}
	\epsilon_{um} &= L_u \cdot R_m + (w_u + w_m) \cdot \phi(m) + b_u + b_m - r_{um}
\end{align}

\begin{center}
and $\eta$ is the learning rate.
\end{center}

\textbf{Stopping criteria.}   We iterate on the stochastic gradient descent
for a maximum of 30 rounds (20 rounds for the validation phase--due to
computing limitation)   or if the changes in rmse falls below 0.005.

\section{Parallelization Scheme and Implementation}

% \begin{figure}[ht]
% \centering
% \includegraphics[width=\linewidth]{figures/dsgdnomad}
% \caption{\label{fig:dsgdnomad} Illustration of DSGD and NOMAD algorithms.  (Modified from~\cite{yun2013nomad})}
% \end{figure}

\subsection{Distributed Stochastic Gradient Descent (DSGD)}

We implement a variant of DSGD\cite{gemulla2011large} which is a bulk
synchronization strategy. We split the rating matrix into $n \times n$ sub-
matrices. In each sub iterations, we can find independent sub matrices in each
row such that variables to be updated are completely disjoint. In our
implementation, we randomly shuffle rows and columns corresponding to movies
and users in the rating matrix to reduce the skewness of the matrix entires
and make the distribution more uniform. Then we employ a simple scheduler
where the $j^{th}$ sub-matrix in row $i$ will be processed at time $(i+j)$ mod
$n$ to ensure independence.

\begin{figure}[h]
\centering
\includegraphics[width=3in]{figures/split.pdf}
\caption{\label{fig:split} Paralellizing the rating matrix with 5 processors. Sub-iterations are indicated by different colors. Each worker 1, 2, \ldots, 5 runs SGD on its own active area. }
\end{figure}

We implemented DSGD entirely in C++. Since DSGD requires no communication
between processing units except synchronization at the end of each sub
iteration, the implementation is relatively simple and is done using OpenMP
shared-memory multiprocessing library. We also use an optimized Math library
(Eigen) to peform fast matrix / vector operations.

\subsection{Non-locking Stochastic Multi-machine Algorithm for Asynchronous and Decentralized Matrix Completion (NOMAD)}

\begin{figure}[h]
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{figures/nomad-alg}
    \vspace{15pt}
  \end{subfigure}%
  ~ %add desired spacing between images, e. g. ~, \quad, \qquad, \hfill etc.
    %(or a blank line to force the subfigure onto a new line)
  \begin{subfigure}[b]{0.5\textwidth}
    \includegraphics[width=\textwidth]{figures/nomad}
    \label{fig:nomad}
  \end{subfigure}
  \vspace{-20pt}
  \caption{Pseudo-code (left) and Illustration (right) NOMAD algorithm (from ~\cite{yun2013nomad}).}\label{fig:nomad}
\end{figure}

We implement NOMAD \cite{yun2013nomad} described in Figure \ref{fig:nomad} in
C++. Please refer to the paper for full description. NOMAD requires each
worker to communicate with other workers via shared thread-safe queues to
notify them of new tasks. We implement this using C++ POSIX threads with
standard concurrent locks. Initial assignments of tasks are randomly
distributed across all workers. In addition, we use dynamic load balancing by
changing line 22 in Figure \ref{fig:nomad} to assign the current task to the
worker with the smallest queue size. This no longer ensures sequential
consistency as some ratings can be processed twice before some other ratings.
However, we are able to gain up to approximately 40\% faster convergence speed compared to the original random assignment due to the more balanced work-load. This
improvement varies across different machines due to the different hardwards
and CPU scheduling algorithms.

\subsection{GraphLab}

We implement another version of parallel SGD using
GraphLab Create by using edge-centric update \texttt{triple\_apply} function, which visit each edge once in parallel with locks on vertices.
Basically, no edges with the same vertex will updated concurrently.

The matrix is modeled as a bi-partite graph between users and movies vertices.
Edge between user $u$ and movie $m$ contains a rating of movie $m$ by user $u$
($r_{um}$). Each user vertex $u$ contains latent factor vector $L_u$, weight
vector $w_u$ and the bias term $b_u$. Similarly, each movie vertex $m$
contains latent factor vector ($R_m$), weight vector $w_m$ and the bias term
$b_m$ but also includes the feature vector $\phi(m)$.  The update function
 basically updates data in source and sink vertices using equations (\ref{eq:update1st})-(\ref{eq:updatelast}).

\section{Experiments for Parallelizing SGD}

Here we present subset of our experimental results from parallelizing SGD.

In all of our experiments,  we initialize the latent matrices $U$ and $M$ by drawing a sample from a uniform distribution in the range $\left[0,\sqrt{\frac{\bar{r}}{0.25k}}\right)$ for each entry in the matrices where $\bar{r}$ is the average rating and $k$ is the matrix rank. Thus, $E[\hat{r}_{um}^0] = \bar{r}$.

\subsection{Performance}


\begin{figure}[ht]
\centering
\includegraphics[width=\linewidth]{figures/performance}
\caption{\label{fig:performance} Drop in RMSE from running SGD with different parallelization scheme for: (a) different implementation during just over 200 seconds, (b, c): NOMAD with and without dynamic load balancing.}
\end{figure}

We first run performance comparison to determine the best algorithm for
searching for optimal parameters and comparing results  between pure and
hybrid matrix factorization models.
We run all the algorithm on single machine \todo{… please put machine description here …}.

Due to limit time, we run different implementations of SGD using the
validating dataset ($D_s^*$) and output RMSE at end the of each epoch expect
for NOMAD which is harder to detect when an epoch has ended so we choose to
print RMSE every 5 seconds instead.  Figure~\ref{fig:performance}(a) shows the
converging pattern for different implementations over the first 200 seconds.
GraphLab which is implemented in python is the slowest as it only finishes 4
epochs and reach $RMSE_{train}=0.852$ during the period.  Meanwhile, single-
thread SGD in C++ finish about 4 epochs and reach $RMSE_{train}=0.825$.
Parallelizing with DSGD leads to about 7 times speed up as the algorithm
finishes 29 epochs during the same amount of time and reach
$RMSE_{train}=0.701$. NOMAD further improve the performance as reach
$RMSE_{train}=0.643$.

Figure~\ref{fig:performance}(b) shows faster convergence rate of our NOMAD implementation with dynamic load balancing in comparison to the original NOMAD.  The table shows that it approximately takes 40\% more time to achieve the same level of RMSE without dynamic load balaning.

\subsection{Hyperparameter Optimization}

We run a grid search to optimize hyperparameters for both pure and hybrid
matrix factorization. Due to the resource limitation, we search for optimal
hyperparameters using a sampled submatrix $D_s^*$ and DSGD algorithm where the
number of iterations or epochs can be deterministcally limited to some value
(as opposed to NOMAD).

We search over $k \in \{5, 10, 20\}$, $\lambda \in \{
0.001, 0.01, 0.1, 1, 10\}$ for both formulation and $\lambda_m \in \{
0.001, 0.01, 0.1, 1, 10\}$ for the hybrid model.  Figure~\ref{fig:gridsearch} shows resulting $rmse_{validate}$ from the grid search.  For both formulation, the optimal $rmse_{validate}$ are obtained when
$k=20$, $\lambda=0.1$ and $\lambda_w=0.1$ (for the hybrid model).

\begin{figure}[h]
\centering
\includegraphics[width=4.2in]{figures/grid}
\caption{\label{fig:gridsearch} Heatmap Table showing $rmse_{validate}$ from
running grid search for different parameters $k$, $\lambda$, $\lambda_m$ for
both pure MF (left) and hybrid MF (right) using 1M subset of the training data.  Lower $rmse$
values are shown in green while high values are shown in red.  Optimal $rmse$
for each formulation are highlighted with a bold text and thick border.}
\end{figure}

\subsection{Comparing the two formulations with Standard Dataset}

Using the optimal parameters from the previous section, we run SGD with DSGD
to compare results between pure and hybrid matrix factorization. For
comparison purposes, we again use DSGD as it has a more deterministic update
routine which allows us to fairly limit the number of iterations for both
formulations.

As a baseline, we predict all ratings equals to the average rating of the whole training set and achieve $RMSE_{test}=1.053$. The pure matrix factorization leads to $RMSE_{test}=0.826$ while the hybrid matrix factoration achieve a $RMSE_{test}=0.822$.

Both models lead to about $20\%$ decrease in $RMSE_test$ from the baseline
However, the hybrid model only leads to minor improvement from pure matrix factorization ($0.48\%$) .  We believe that this is due
to the fact that our data set only contains genres and tags, which might not
be the most predictive features for movie ratings.  Mining for other metadata
from websites such as IMDB might enhance the improvement from the hybrid
model.

\subsection{Experimenting for Cold-start Problem}

\todo{supasorn please write}

\section{Lessons Learned}

Also, implementing DSGD and NOMAD in C++ leads to roughly \todo{XXXX times} speed-ups.

In our earlier implementation, we did not normalize ratings and normalize

\section{Acknowledgement}
We use figures from \cite{yun2013nomad} for DSGD and NOMAD algorithm descriptions.

\bibliographystyle{abbrv}
\bibliography{paper_supasorn_kanitw}{}
\end{document}

